{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16f82fcc",
   "metadata": {},
   "source": [
    "# Install and import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3f5e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\prashant\\documents\\nitin\\projects\\.venv\\lib\\site-packages (2.7.0+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\prashant\\documents\\nitin\\projects\\.venv\\lib\\site-packages (0.22.0+cu118)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\prashant\\documents\\nitin\\projects\\.venv\\lib\\site-packages (2.7.0+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\prashant\\documents\\nitin\\projects\\.venv\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\prashant\\documents\\nitin\\projects\\.venv\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\prashant\\documents\\nitin\\projects\\.venv\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\prashant\\documents\\nitin\\projects\\.venv\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\prashant\\documents\\nitin\\projects\\.venv\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\prashant\\documents\\nitin\\projects\\.venv\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\prashant\\documents\\nitin\\projects\\.venv\\lib\\site-packages (from torch) (70.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\prashant\\documents\\nitin\\projects\\.venv\\lib\\site-packages (from torchvision) (2.2.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\prashant\\documents\\nitin\\projects\\.venv\\lib\\site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\prashant\\documents\\nitin\\projects\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\prashant\\documents\\nitin\\projects\\.venv\\lib\\site-packages (from jinja2->torch) (2.1.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install PyTorch with CUDA 11.8 support\n",
    "# This installs PyTorch deep learning library with GPU acceleration capabilities\n",
    "\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc47375c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Prashant\\Documents\\Nitin\\Projects\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "# transformers: Hugging Face library for pre-trained models\n",
    "# torch: PyTorch deep learning framework\n",
    "# requests: For making HTTP requests\n",
    "# re: For regular expressions\n",
    "# pandas: For data manipulation and analysis\n",
    "# numpy: For numerical operations\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4078a8e1",
   "metadata": {},
   "source": [
    "# Instantiate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f439486",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Prashant\\Documents\\Nitin\\Projects\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Prashant\\.cache\\huggingface\\hub\\models--nlptown--bert-base-multilingual-uncased-sentiment. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained tokenizer for multilingual sentiment analysis\n",
    "# This tokenizer converts text into tokens that the model can understand\n",
    "# The model is trained to handle sentiment analysis in multiple languages\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "\n",
    "# Load the pre-trained sentiment analysis model\n",
    "# This model is fine-tuned to classify text into 5 sentiment levels (1-5 stars)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7741e2b",
   "metadata": {},
   "source": [
    "# Encode and calculate sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2b1797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model with a sample sentence\n",
    "# Convert the text to tokens that the model can process\n",
    "# return_tensors='pt' means return PyTorch tensors\n",
    "\n",
    "tokens = tokenizer.encode('It was good but couldve been better. Great', return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd34b8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the tokens through the model to get sentiment predictions\n",
    "\n",
    "result = model(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35828bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.7768, -1.2353,  1.4419,  1.9804,  0.4584]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the raw logits (prediction scores before softmax)\n",
    "# These are the unnormalized scores for each sentiment class\n",
    "\n",
    "result.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79964df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the predicted sentiment score\n",
    "# torch.argmax finds the position with highest value\n",
    "# Add 1 because the model outputs 0-4 but we want 1-5 star ratings\n",
    "\n",
    "int(torch.argmax(result.logits))+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ff656f",
   "metadata": {},
   "source": [
    "# Loada the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b435b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Amazon reviews dataset from a CSV file\n",
    "# This dataset contains reviews that we'll analyze for sentiment\n",
    "\n",
    "amazon_reviews_df = pd.read_csv(r'C:\\Users\\Prashant\\Documents\\Nitin\\Projects\\7817_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d232ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'asins', 'brand', 'categories', 'colors', 'dateAdded',\n",
       "       'dateUpdated', 'dimension', 'ean', 'keys', 'manufacturer',\n",
       "       'manufacturerNumber', 'name', 'prices', 'reviews.date',\n",
       "       'reviews.doRecommend', 'reviews.numHelpful', 'reviews.rating',\n",
       "       'reviews.sourceURLs', 'reviews.text', 'reviews.title',\n",
       "       'reviews.userCity', 'reviews.userProvince', 'reviews.username', 'sizes',\n",
       "       'upc', 'weight'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the column names to understand the dataset structure\n",
    "\n",
    "amazon_reviews_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac6a20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a reference to the loaded DataFrame\n",
    "\n",
    "reviews = amazon_reviews_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0287fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only the review text column for sentiment analysis\n",
    "\n",
    "reviews = reviews[['reviews.text']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629d259b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame with the review texts\n",
    "# Converting to numpy array first and then back to DataFrame\n",
    "# This creates a clean DataFrame with just one column named 'review'\n",
    "\n",
    "df = pd.DataFrame(np.array(reviews), columns=['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69495a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I initially had trouble deciding between the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allow me to preface this with a little history...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am enjoying it so far. Great for reading. Ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I bought one of the first Paperwhites and have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have to say upfront - I don't like coroporat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review\n",
       "0  I initially had trouble deciding between the p...\n",
       "1  Allow me to preface this with a little history...\n",
       "2  I am enjoying it so far. Great for reading. Ha...\n",
       "3  I bought one of the first Paperwhites and have...\n",
       "4  I have to say upfront - I don't like coroporat..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows to verify the data\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f50d04",
   "metadata": {},
   "source": [
    "# Calculate the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bef860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I initially had trouble deciding between the paperwhite and the voyage because reviews more or less said the same thing: the paperwhite is great, but if you have spending money, go for the voyage.Fortunately, I had friends who owned each, so I ended up buying the paperwhite on this basis: both models now have 300 ppi, so the 80 dollar jump turns out pricey the voyage's page press isn't always sensitive, and if you are fine with a specific setting, you don't need auto light adjustment).It's been a week and I am loving my paperwhite, no regrets! The touch screen is receptive and easy to use, and I keep the light at a specific setting regardless of the time of day. (In any case, it's not hard to change the setting either, as you'll only be changing the light level at a certain time of day, not every now and then while reading).Also glad that I went for the international shipping option with Amazon. Extra expense, but delivery was on time, with tracking, and I didnt need to worry about customs, which I may have if I used a third party shipping service.\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the first review in the DataFrame\n",
    "\n",
    "df['review'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0f8323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate sentiment scores for any review text\n",
    "\n",
    "def sentiment_score(review):\n",
    "    tokens = tokenizer.encode(review, return_tensors='pt')\n",
    "    result = model(tokens)\n",
    "    return int(torch.argmax(result.logits))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6472071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the sentiment_score function on the second review\n",
    "\n",
    "sentiment_score(df['review'].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a21e06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the sentiment_score function to all reviews in the DataFrame\n",
    "# The [:512] limits each review to 512 tokens as BERT has a maximum input length\n",
    "# This creates a new column 'sentiment' with scores 1-5 for each review\n",
    "\n",
    "df['sentiment'] = df['review'].apply(lambda x: sentiment_score(x[:512]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177af1b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I initially had trouble deciding between the p...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allow me to preface this with a little history...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am enjoying it so far. Great for reading. Ha...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I bought one of the first Paperwhites and have...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have to say upfront - I don't like coroporat...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>This is not the same remote that I got for my ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>I have had to change the batteries in this rem...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>Remote did not activate, nor did it connect to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>It does the job but is super over priced. I fe...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>I ordered this item to replace the one that no...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1597 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review  sentiment\n",
       "0     I initially had trouble deciding between the p...          4\n",
       "1     Allow me to preface this with a little history...          4\n",
       "2     I am enjoying it so far. Great for reading. Ha...          4\n",
       "3     I bought one of the first Paperwhites and have...          4\n",
       "4     I have to say upfront - I don't like coroporat...          2\n",
       "...                                                 ...        ...\n",
       "1592  This is not the same remote that I got for my ...          2\n",
       "1593  I have had to change the batteries in this rem...          1\n",
       "1594  Remote did not activate, nor did it connect to...          1\n",
       "1595  It does the job but is super over priced. I fe...          3\n",
       "1596  I ordered this item to replace the one that no...          1\n",
       "\n",
       "[1597 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the DataFrame with both reviews and their sentiment scores\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deba5c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I bought one of the first Paperwhites and have been very pleased with it its been a constant companion and I suppose Ive read, on average, a book every three days for the past however many years on it. I wouldnt give it up youd have to pry it from my cold dead fingers.For sundry logistical reasons, Ive also made good use of Amazons Kindle app on my iPhone. No Paperwhite screen, naturally, and all the cool usability that delivers, but it works well and has its own attractions as a companion to the Kindle.Of course, there are aspects of the Paperwhite which I would like to critique. Ah you knew that was coming somewhere, didnt you.As a member of BookBub, I get a daily list of alerts and book deals in my chosen genres. I take on many of them, however, Ive found that, even with the best will in the world, I cant keep up. Some days it seems that for every book I read, Ive bought two. Theres just so much good stuff out there! The accumulative effect of this is that the number of books actually on my Paperwhite has been creeping ever upward for some time. Its now at about 400.With this in mind, Ive noticed that while page-turning has remained exactly the same, just about every other action on the Kindle has become positively glacial. Not just very slow, but so slow you think its malfunctioning. The general consensus appears to be that its to be expected once one has that many books downloaded onto a Kindle, it will begin to behave in a flakey manner. This drives me mad. Amazon states it can hold thousands of books. I believe them. But I figure I would need a second Paperwhite to read while Im waiting for actions to complete on the first one.Read more'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the fourth review text to examine it\n",
    "\n",
    "df['review'].iloc[3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
